2025-06-23:11:54:45,455 INFO     [config.py:59] PyTorch version 2.5.1+cu121 available.
2025-06-23:11:54:48,218 INFO     [__main__.py:132] Verbosity set to INFO
2025-06-23:11:54:55,126 INFO     [__main__.py:205] Selected Tasks: ['arc_challenge', 'arc_easy', 'lambada_openai', 'logiqa', 'piqa', 'sciq', 'wikitext', 'winogrande', 'wsc']
2025-06-23:11:54:55,129 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-06-23:11:54:57,220 INFO     [huggingface.py:120] Using device 'cuda:0'
/home/txiao/miniconda3/envs/py39_cu121_torch251_new2/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2025-06-23:11:55:07,267 WARNING  [huggingface.py:284] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 1 devices.
2025-06-23:11:55:17,093 WARNING  [task.py:300] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-06-23:11:55:17,093 WARNING  [task.py:300] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-06-23:11:55:26,295 WARNING  [task.py:614] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2025-06-23:11:55:26,295 WARNING  [task.py:626] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2025-06-23:11:55:26,295 WARNING  [task.py:614] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2025-06-23:11:55:26,295 WARNING  [task.py:626] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2025-06-23:11:55:26,295 WARNING  [task.py:614] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2025-06-23:11:55:26,295 WARNING  [task.py:626] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2025-06-23:11:55:32,240 WARNING  [task.py:614] [Task: wsc] metric acc is defined, but aggregation is not. using default aggregation=mean
2025-06-23:11:55:32,240 WARNING  [task.py:626] [Task: wsc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of arc_challenge from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of arc_easy from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of lambada_openai from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of logiqa from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of piqa from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of sciq from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of wikitext from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of winogrande from None to 5
2025-06-23:11:55:36,316 WARNING  [evaluator.py:143] Overwriting default num_fewshot of wsc from None to 5
2025-06-23:11:55:36,316 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:55:46,459 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:56:07,370 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:56:48,610 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:56:49,443 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:56:56,481 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:57:02,128 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:57:02,664 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:57:02,735 INFO     [task.py:355] Building contexts for task on rank 0...
2025-06-23:11:57:02,747 INFO     [evaluator.py:319] Running loglikelihood requests
Warnings:>>> `self.Layer_num: int` (12), i.e., the number of layers of the current LM, must be correctly set!
############################################ Basic Args for SepAttention ############################################
self.USE_PREFILL_LOCAL_WIN_SIZES_wrt_LAYERS:  True
self.prefill_loc_win_size_list: [2048, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 2048]
self.USE_GENERATE_LOCAL_WIN_SIZES_wrt_LAYERS:  True
self.generate_win_loc_size_list: [2048, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 2048]
self.PADDING_ID: 0 --- Must be correctly set.
self.Layer_num: 12 --- Must be correctly set.
self.init_tok_max_idx: 2
self.USE_ORIGINAL_FULL_ATTEN:  False
self.streamingLLM:  False
self.BATCH_ADAPTIVE_INIT_POS:  False
>>> For `BATCH_ADAPTIVE_INIT_POS`: Typically True when the input_ids of the model use 'left padding', False for 'right padding' (e.g., for training or some downstream tasks like `lambada_openai`, `piqa`, etc).
self.PRINT_KV_RATIO:  True
self.print_ratio_intervals:  100
>>> Please be careful of the `separator_token_ids`, and make sure they are correct for the current LLM
self.separator_token_ids: [15, 13, 32, 2, 28, 27, 209, 186, 187]
self.USE_BiPE: False
self.EXCLUDE_DIAGONAL:  True
>>>>>>>>---------##########################################################-----------<<<<<<<<
>>>>>>>>---------                                                          -----------<<<<<<<<
>>>>>>>>--------------------- Running our SepLLM strategy ----------------------------<<<<<<<<
>>>>>>>>---------                                                          -----------<<<<<<<<
>>>>>>>>---------##########################################################-----------<<<<<<<<
  0%|          | 0/32363 [00:00<?, ?it/s]  0%|          | 1/32363 [00:02<18:22:21,  2.04s/it]  0%|          | 33/32363 [00:02<25:41, 20.97it/s]    0%|          | 65/32363 [00:02<11:50, 45.49it/s]  0%|          | 97/32363 [00:02<07:19, 73.48it/s]  0%|          | 129/32363 [00:02<05:10, 103.93it/s]  0%|          | 161/32363 [00:02<03:56, 136.42it/s]  1%|          | 193/32363 [00:02<03:11, 167.77it/s]  1%|          | 225/32363 [00:02<02:42, 197.86it/s]  1%|          | 257/32363 [00:02<02:22, 224.58it/s]  1%|          | 289/32363 [00:03<02:09, 247.57it/s]  1%|          | 331/32363 [00:03<01:49, 291.83it/s]  1%|          | 380/32363 [00:03<01:32, 344.96it/s]  1%|▏         | 419/32363 [00:03<01:51, 285.47it/s]  1%|▏         | 481/32363 [00:03<01:45, 302.93it/s]  2%|▏         | 545/32363 [00:03<01:40, 316.38it/s]  2%|▏         | 609/32363 [00:03<01:37, 325.29it/s]  2%|▏         | 673/32363 [00:04<01:34, 333.85it/s]  2%|▏         | 737/32363 [00:04<01:32, 342.63it/s]  2%|▏         | 801/32363 [00:04<01:30, 348.49it/s]  3%|▎         | 865/32363 [00:04<01:29, 352.07it/s]  3%|▎         | 929/32363 [00:04<01:28, 356.09it/s]  3%|▎         | 993/32363 [00:05<01:27, 359.39it/s]  3%|▎         | 1057/32363 [00:05<01:26, 362.79it/s]  3%|▎         | 1121/32363 [00:05<01:24, 367.96it/s]  4%|▎         | 1185/32363 [00:05<01:23, 372.47it/s]  4%|▍         | 1249/32363 [00:05<01:22, 378.17it/s]  4%|▍         | 1313/32363 [00:05<01:21, 380.67it/s]  4%|▍         | 1377/32363 [00:06<01:20, 383.93it/s]  4%|▍         | 1441/32363 [00:06<01:19, 386.86it/s]  5%|▍         | 1505/32363 [00:06<01:19, 389.87it/s]  5%|▍         | 1569/32363 [00:06<01:18, 394.21it/s]  5%|▌         | 1633/32363 [00:06<01:16, 399.39it/s]  5%|▌         | 1697/32363 [00:06<01:16, 402.47it/s]  5%|▌         | 1761/32363 [00:06<01:15, 405.72it/s]  6%|▌         | 1825/32363 [00:07<01:14, 409.43it/s]  6%|▌         | 1889/32363 [00:07<01:13, 413.04it/s]  6%|▌         | 1953/32363 [00:07<01:12, 417.50it/s]  6%|▌         | 2017/32363 [00:07<01:12, 420.04it/s]  6%|▋         | 2081/32363 [00:07<01:11, 422.22it/s]  7%|▋         | 2145/32363 [00:07<01:10, 427.41it/s]  7%|▋         | 2209/32363 [00:08<01:09, 432.38it/s]  7%|▋         | 2273/32363 [00:08<01:08, 436.60it/s]  7%|▋         | 2337/32363 [00:08<01:08, 440.80it/s]  7%|▋         | 2401/32363 [00:08<01:07, 444.94it/s]  8%|▊         | 2465/32363 [00:08<01:06, 449.24it/s]  8%|▊         | 2529/32363 [00:08<01:05, 458.70it/s]  8%|▊         | 2593/32363 [00:08<01:03, 465.41it/s]  8%|▊         | 2657/32363 [00:08<01:02, 474.64it/s]  8%|▊         | 2721/32363 [00:09<01:01, 480.39it/s]  9%|▊         | 2785/32363 [00:09<01:00, 488.13it/s]  9%|▉         | 2849/32363 [00:09<00:59, 497.48it/s]  9%|▉         | 2913/32363 [00:09<00:58, 506.90it/s]  9%|▉         | 2977/32363 [00:09<00:57, 515.04it/s]  9%|▉         | 3041/32363 [00:09<00:56, 522.69it/s] 10%|▉         | 3105/32363 [00:09<00:54, 536.37it/s]
###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (116308, 359040), ratio: 0.3239 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (14878214, 46705536), ratio: 0.3186 
 10%|▉         | 3169/32363 [00:09<00:53, 547.37it/s] 10%|▉         | 3233/32363 [00:10<00:52, 557.85it/s] 10%|█         | 3297/32363 [00:10<00:50, 570.50it/s] 10%|█         | 3361/32363 [00:10<00:49, 586.87it/s] 11%|█         | 3425/32363 [00:10<00:48, 600.19it/s] 11%|█         | 3508/32363 [00:10<00:43, 665.92it/s] 11%|█         | 3585/32363 [00:10<00:45, 625.96it/s] 11%|█▏        | 3681/32363 [00:10<00:44, 649.12it/s] 12%|█▏        | 3777/32363 [00:10<00:42, 672.60it/s] 12%|█▏        | 3873/32363 [00:11<00:40, 695.61it/s] 12%|█▏        | 3969/32363 [00:11<00:39, 715.15it/s] 13%|█▎        | 4065/32363 [00:11<00:38, 735.15it/s] 13%|█▎        | 4161/32363 [00:11<00:37, 758.53it/s] 13%|█▎        | 4257/32363 [00:11<00:36, 780.31it/s] 13%|█▎        | 4353/32363 [00:11<00:35, 799.75it/s] 14%|█▎        | 4449/32363 [00:11<00:33, 821.33it/s] 14%|█▍        | 4545/32363 [00:11<00:33, 842.16it/s] 14%|█▍        | 4641/32363 [00:11<00:32, 865.80it/s] 15%|█▍        | 4737/32363 [00:12<00:31, 885.82it/s] 15%|█▍        | 4843/32363 [00:12<00:29, 935.09it/s] 15%|█▌        | 4954/32363 [00:12<00:27, 985.57it/s] 16%|█▌        | 5057/32363 [00:12<00:29, 924.81it/s] 16%|█▌        | 5185/32363 [00:12<00:28, 958.24it/s] 16%|█▋        | 5313/32363 [00:12<00:27, 986.10it/s] 17%|█▋        | 5441/32363 [00:12<00:26, 1006.90it/s] 17%|█▋        | 5569/32363 [00:12<00:26, 1023.93it/s] 18%|█▊        | 5697/32363 [00:12<00:25, 1039.18it/s] 18%|█▊        | 5825/32363 [00:13<00:25, 1052.61it/s] 18%|█▊        | 5953/32363 [00:13<00:24, 1065.27it/s] 19%|█▉        | 6081/32363 [00:13<00:24, 1073.67it/s] 19%|█▉        | 6209/32363 [00:13<00:24, 1080.67it/s] 20%|█▉        | 6337/32363 [00:13<00:23, 1087.95it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (74512, 202752), ratio: 0.3675 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (23508798, 71701632), ratio: 0.3279 
 20%|█▉        | 6465/32363 [00:13<00:23, 1094.54it/s] 20%|██        | 6593/32363 [00:13<00:23, 1099.13it/s] 21%|██        | 6721/32363 [00:13<00:23, 1104.06it/s] 21%|██        | 6849/32363 [00:14<00:22, 1111.75it/s] 22%|██▏       | 6977/32363 [00:14<00:22, 1115.20it/s] 22%|██▏       | 7105/32363 [00:14<00:22, 1118.35it/s] 22%|██▏       | 7233/32363 [00:14<00:22, 1121.59it/s] 23%|██▎       | 7361/32363 [00:14<00:22, 1130.72it/s] 23%|██▎       | 7489/32363 [00:14<00:21, 1141.36it/s] 24%|██▎       | 7617/32363 [00:14<00:21, 1150.35it/s] 24%|██▍       | 7745/32363 [00:14<00:21, 1157.17it/s] 24%|██▍       | 7873/32363 [00:14<00:21, 1162.59it/s] 25%|██▍       | 8001/32363 [00:14<00:20, 1168.75it/s] 25%|██▌       | 8129/32363 [00:15<00:20, 1173.39it/s] 26%|██▌       | 8257/32363 [00:15<00:20, 1177.26it/s] 26%|██▌       | 8385/32363 [00:15<00:20, 1180.35it/s] 26%|██▋       | 8513/32363 [00:15<00:20, 1183.24it/s] 27%|██▋       | 8641/32363 [00:15<00:19, 1189.18it/s] 27%|██▋       | 8769/32363 [00:15<00:19, 1192.50it/s] 27%|██▋       | 8897/32363 [00:15<00:19, 1195.97it/s] 28%|██▊       | 9025/32363 [00:15<00:19, 1198.36it/s] 28%|██▊       | 9153/32363 [00:15<00:19, 1200.13it/s] 29%|██▊       | 9281/32363 [00:16<00:19, 1206.41it/s] 29%|██▉       | 9409/32363 [00:16<00:19, 1206.94it/s] 29%|██▉       | 9537/32363 [00:16<00:18, 1208.23it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (71012, 185856), ratio: 0.3821 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (30787106, 91060608), ratio: 0.3381 
 30%|██▉       | 9665/32363 [00:16<00:18, 1209.08it/s] 30%|███       | 9793/32363 [00:16<00:18, 1214.92it/s] 31%|███       | 9921/32363 [00:16<00:18, 1221.41it/s] 31%|███       | 10049/32363 [00:16<00:18, 1226.15it/s] 31%|███▏      | 10177/32363 [00:16<00:18, 1231.01it/s] 32%|███▏      | 10305/32363 [00:16<00:17, 1237.62it/s] 32%|███▏      | 10433/32363 [00:17<00:17, 1241.75it/s] 33%|███▎      | 10561/32363 [00:17<00:17, 1241.41it/s] 33%|███▎      | 10689/32363 [00:17<00:17, 1248.80it/s] 33%|███▎      | 10817/32363 [00:17<00:17, 1253.24it/s] 34%|███▍      | 10945/32363 [00:17<00:17, 1259.17it/s] 34%|███▍      | 11092/32363 [00:17<00:16, 1321.64it/s] 35%|███▍      | 11233/32363 [00:17<00:16, 1280.42it/s] 35%|███▌      | 11393/32363 [00:17<00:15, 1314.58it/s] 36%|███▌      | 11553/32363 [00:17<00:15, 1353.15it/s] 36%|███▌      | 11713/32363 [00:17<00:14, 1402.94it/s] 37%|███▋      | 11873/32363 [00:18<00:14, 1453.19it/s] 37%|███▋      | 12059/32363 [00:18<00:12, 1569.90it/s] 38%|███▊      | 12225/32363 [00:18<00:13, 1539.20it/s] 38%|███▊      | 12417/32363 [00:18<00:12, 1607.04it/s] 39%|███▉      | 12609/32363 [00:18<00:11, 1663.42it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (52156, 114816), ratio: 0.4543 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (37173434, 106834176), ratio: 0.3480 
 40%|███▉      | 12801/32363 [00:18<00:11, 1714.47it/s] 40%|████      | 12993/32363 [00:18<00:11, 1754.73it/s] 41%|████      | 13185/32363 [00:18<00:10, 1791.64it/s] 41%|████▏     | 13377/32363 [00:18<00:10, 1820.95it/s] 42%|████▏     | 13569/32363 [00:19<00:10, 1848.29it/s] 43%|████▎     | 13774/32363 [00:19<00:09, 1907.61it/s] 43%|████▎     | 13985/32363 [00:19<00:09, 1895.45it/s] 44%|████▍     | 14197/32363 [00:19<00:09, 1960.14it/s] 44%|████▍     | 14401/32363 [00:19<00:09, 1921.81it/s] 45%|████▌     | 14625/32363 [00:19<00:09, 1945.67it/s] 46%|████▌     | 14849/32363 [00:19<00:08, 1981.08it/s] 47%|████▋     | 15073/32363 [00:19<00:08, 2011.75it/s] 47%|████▋     | 15297/32363 [00:19<00:08, 2036.09it/s] 48%|████▊     | 15521/32363 [00:19<00:08, 2061.86it/s] 49%|████▊     | 15745/32363 [00:20<00:07, 2081.64it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (47094, 92544), ratio: 0.5089 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (42079176, 116974848), ratio: 0.3597 
 49%|████▉     | 15969/32363 [00:20<00:07, 2098.73it/s] 50%|█████     | 16193/32363 [00:20<00:07, 2113.70it/s] 51%|█████     | 16417/32363 [00:20<00:07, 2126.72it/s] 51%|█████▏    | 16641/32363 [00:20<00:07, 2136.55it/s] 52%|█████▏    | 16865/32363 [00:20<00:07, 2146.00it/s] 53%|█████▎    | 17089/32363 [00:20<00:07, 2152.89it/s] 53%|█████▎    | 17313/32363 [00:20<00:06, 2164.08it/s] 54%|█████▍    | 17537/32363 [00:20<00:06, 2172.83it/s] 55%|█████▍    | 17761/32363 [00:20<00:06, 2181.45it/s] 56%|█████▌    | 17985/32363 [00:21<00:06, 2195.09it/s] 56%|█████▋    | 18209/32363 [00:21<00:06, 2204.24it/s] 57%|█████▋    | 18433/32363 [00:21<00:06, 2212.49it/s] 58%|█████▊    | 18657/32363 [00:21<00:06, 2215.38it/s] 58%|█████▊    | 18882/32363 [00:21<00:06, 2225.12it/s] 59%|█████▉    | 19105/32363 [00:21<00:05, 2225.90it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (44424, 82944), ratio: 0.5356 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (46620226, 125712384), ratio: 0.3708 
 60%|█████▉    | 19330/32363 [00:21<00:05, 2232.60it/s] 60%|██████    | 19554/32363 [00:21<00:05, 2233.27it/s] 61%|██████    | 19785/32363 [00:21<00:05, 2256.05it/s] 62%|██████▏   | 20018/32363 [00:22<00:05, 2277.75it/s] 63%|██████▎   | 20257/32363 [00:22<00:05, 2235.68it/s] 63%|██████▎   | 20509/32363 [00:22<00:05, 2318.84it/s] 64%|██████▍   | 20742/32363 [00:22<00:05, 2259.41it/s] 65%|██████▍   | 20993/32363 [00:22<00:05, 2259.02it/s] 66%|██████▌   | 21247/32363 [00:22<00:04, 2339.56it/s] 66%|██████▋   | 21482/32363 [00:22<00:04, 2279.19it/s] 67%|██████▋   | 21729/32363 [00:22<00:04, 2267.13it/s] 68%|██████▊   | 21985/32363 [00:22<00:04, 2289.24it/s] 69%|██████▊   | 22241/32363 [00:22<00:04, 2307.53it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (42378, 75648), ratio: 0.5602 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (50949836, 133633152), ratio: 0.3813 
 70%|██████▉   | 22497/32363 [00:23<00:04, 2318.99it/s] 70%|███████   | 22753/32363 [00:23<00:04, 2323.97it/s] 71%|███████   | 23009/32363 [00:23<00:04, 2333.19it/s] 72%|███████▏  | 23265/32363 [00:23<00:03, 2347.50it/s] 73%|███████▎  | 23521/32363 [00:23<00:03, 2366.21it/s] 73%|███████▎  | 23777/32363 [00:23<00:03, 2384.70it/s] 74%|███████▍  | 24033/32363 [00:23<00:03, 2397.63it/s] 75%|███████▌  | 24289/32363 [00:23<00:03, 2412.68it/s] 76%|███████▌  | 24545/32363 [00:23<00:03, 2425.22it/s] 77%|███████▋  | 24801/32363 [00:24<00:03, 2438.89it/s] 77%|███████▋  | 25057/32363 [00:24<00:02, 2452.13it/s] 78%|███████▊  | 25313/32363 [00:24<00:02, 2459.44it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (40776, 68736), ratio: 0.5932 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (55090580, 140849664), ratio: 0.3911 
 79%|███████▉  | 25569/32363 [00:24<00:02, 2467.97it/s] 80%|███████▉  | 25825/32363 [00:24<00:02, 2478.79it/s] 81%|████████  | 26086/32363 [00:24<00:02, 2516.82it/s] 81%|████████▏ | 26346/32363 [00:24<00:02, 2540.78it/s] 82%|████████▏ | 26605/32363 [00:24<00:02, 2554.89it/s] 83%|████████▎ | 26872/32363 [00:24<00:02, 2588.58it/s] 84%|████████▍ | 27137/32363 [00:24<00:02, 2538.28it/s] 85%|████████▍ | 27419/32363 [00:25<00:01, 2620.52it/s] 86%|████████▌ | 27682/32363 [00:25<00:01, 2568.53it/s] 86%|████████▋ | 27969/32363 [00:25<00:01, 2588.15it/s] 87%|████████▋ | 28257/32363 [00:25<00:01, 2610.81it/s] 88%|████████▊ | 28545/32363 [00:25<00:01, 2627.12it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (37982, 59136), ratio: 0.6423 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (59011326, 147282048), ratio: 0.4007 
 89%|████████▉ | 28833/32363 [00:25<00:01, 2641.96it/s] 90%|████████▉ | 29121/32363 [00:25<00:01, 2654.00it/s] 91%|█████████ | 29409/32363 [00:25<00:01, 2660.28it/s] 92%|█████████▏| 29697/32363 [00:25<00:01, 2657.55it/s] 93%|█████████▎| 29963/32363 [00:26<00:00, 2625.00it/s] 94%|█████████▎| 30273/32363 [00:26<00:00, 2705.93it/s] 95%|█████████▍| 30593/32363 [00:26<00:00, 2793.85it/s] 96%|█████████▌| 30913/32363 [00:26<00:00, 2848.79it/s] 97%|█████████▋| 31233/32363 [00:26<00:00, 2890.10it/s] 97%|█████████▋| 31553/32363 [00:26<00:00, 2926.23it/s] 98%|█████████▊| 31873/32363 [00:26<00:00, 2953.02it/s]

###############################SepAttention: Kept/Total tokens for this input batch#####################################
 (kept, total) : (6912, 6912), ratio: 1.0000 

###############################SepAttention: Kept/Total tokens for all the inputs#######################################
 (kept, total) : (60780352, 149705472), ratio: 0.4060 
 99%|█████████▉| 32193/32363 [00:26<00:00, 2969.38it/s]100%|██████████| 32363/32363 [00:26<00:00, 1206.30it/s]
2025-06-23:11:58:11,527 INFO     [evaluator.py:319] Running loglikelihood_rolling requests

  0%|          | 0/62 [00:00<?, ?it/s]  6%|▋         | 4/62 [00:00<00:01, 38.43it/s] 13%|█▎        | 8/62 [00:00<00:01, 37.63it/s] 19%|█▉        | 12/62 [00:00<00:01, 32.57it/s] 31%|███       | 19/62 [00:00<00:01, 42.25it/s] 39%|███▊      | 24/62 [00:00<00:00, 38.49it/s] 45%|████▌     | 28/62 [00:00<00:00, 36.72it/s] 55%|█████▍    | 34/62 [00:00<00:00, 42.78it/s] 63%|██████▎   | 39/62 [00:01<00:00, 35.42it/s] 69%|██████▉   | 43/62 [00:01<00:00, 33.54it/s] 77%|███████▋  | 48/62 [00:01<00:00, 37.02it/s] 90%|█████████ | 56/62 [00:01<00:00, 47.87it/s]100%|██████████| 62/62 [00:01<00:00, 45.17it/s]100%|██████████| 62/62 [00:01<00:00, 40.30it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:36,  2.73it/s] 17%|█▋        | 17/100 [00:00<00:01, 42.05it/s] 33%|███▎      | 33/100 [00:00<00:01, 63.06it/s] 50%|█████     | 50/100 [00:00<00:00, 89.20it/s] 62%|██████▏   | 62/100 [00:00<00:00, 94.90it/s] 74%|███████▍  | 74/100 [00:01<00:00, 89.88it/s] 91%|█████████ | 91/100 [00:01<00:00, 104.86it/s]100%|██████████| 100/100 [00:01<00:00, 73.56it/s]
fatal: not a git repository (or any parent up to mount point /lustre)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
hf (pretrained=Gausson/pythia-160m-deduped-n64ht-SepLLM), gen_kwargs: (), limit: None, num_fewshot: 5, batch_size: 32
|    Tasks     |Version|Filter|n-shot|    Metric     | Value |   |Stderr|
|--------------|-------|------|-----:|---------------|------:|---|-----:|
|arc_challenge |Yaml   |none  |     5|acc            | 0.2133|±  |0.0120|
|              |       |none  |     5|acc_norm       | 0.2389|±  |0.0125|
|arc_easy      |Yaml   |none  |     5|acc            | 0.4735|±  |0.0102|
|              |       |none  |     5|acc_norm       | 0.4474|±  |0.0102|
|lambada_openai|Yaml   |none  |     5|perplexity     |33.4119|±  |1.1735|
|              |       |none  |     5|acc            | 0.3287|±  |0.0065|
|logiqa        |Yaml   |none  |     5|acc            | 0.2243|±  |0.0164|
|              |       |none  |     5|acc_norm       | 0.2734|±  |0.0175|
|piqa          |Yaml   |none  |     5|acc            | 0.6409|±  |0.0112|
|              |       |none  |     5|acc_norm       | 0.6431|±  |0.0112|
|sciq          |Yaml   |none  |     5|acc            | 0.8130|±  |0.0123|
|              |       |none  |     5|acc_norm       | 0.7950|±  |0.0128|
|wikitext      |Yaml   |none  |     5|word_perplexity|29.1903|   |      |
|              |       |none  |     5|byte_perplexity| 1.8793|   |      |
|              |       |none  |     5|bits_per_byte  | 0.9102|   |      |
|winogrande    |Yaml   |none  |     5|acc            | 0.5051|±  |0.0141|
|wsc           |Yaml   |none  |     5|acc            | 0.4038|±  |0.0483|

